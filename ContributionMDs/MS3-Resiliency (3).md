<table><tr><td> <em>Assignment: </em> IT490 - Milestone 3 - Resiliency</td></tr>
<tr><td> <em>Student: </em> Dominic Quitoni(dwq2)</td></tr>
<tr><td> <em>Generated: </em> 7/28/2022 4:31:31 PM</td></tr>
<tr><td> <em>Grading Link: </em> <a rel="noreferrer noopener" href="https://learn.ethereallab.app/homework/IT490-451-M22/it490-milestone-3-resiliency/grade/dwq2" target="_blank">Grading</a></td></tr></table>
<table><tr><td> <em>Instructions: </em> <p>For this milestone, as a team you&#39;ll be implementing a solution to keep your application running ~99.99% (in theory).<div><br><div><div>In production lane you should already have 4 VMs (app, db, mq, api).</div><div><br></div><div>For this milestone you&#39;ll need to create at least 4 more (1 of each VM type).</div><div><br></div><div>Depending on your solution (discussed below) you may have an additional VM or so.</div><div><br></div><div>Once you have 2 pairs of each VM you&#39;ll come up with a solution for load balancing.</div><div><br></div><div>Note: You do not need to leave all of the production VMs running 24/7, just long enough to setup the solution and gather the evidence</div></div></div><div><br></div><div><p style="margin-top: 12px; margin-bottom: 12px;">Goal:</p><ul style="padding: 0px; margin: 0px 0px 6px 25px;"><li style="">If any VM of a pair goes down, the system should detect this and cleanly reroute traffic to the healthy VM<ul style="padding: 0px; margin: 0px 0px 0px 25px;"><li>If APP A goes down, the user should be routed to APP B without losing their session (i.e., the user shouldn&#39;t notice a VM went down and should not have to relog)</li><li>If MQ A goes down, the remaining VMs should utilize MQ B</li><li>If DB A goes down, DB B should handle the requests</li><li>If API A goes down, API B should handle the requests</li></ul></li><li style="">Likely the load balancing solution will balance the load evenly across the options, so it won&#39;t just be A or B, it&#39;ll be simultaneous and the healthy VM would just take over the connections from the unhealthy one</li><li style="">&nbsp;This will be demonstrated during your final presentation as well</li></ul><div><br></div></div><div><ol><li>Create a new file called&nbsp;resiliency.md</li><li>Create a branch called MS3-Resiliency</li><li>Have each team member research and write about some resiliency solution (everyone should contribute here)<br></li><li>Submit the direct link to the resiliency.md file from the MS3-Resiliency branch to github</li></ol><div><p style="margin-top: 12px; margin-bottom: 12px;"><br></p><p style="margin-top: 12px; margin-bottom: 12px;">Grading will be based on the following</p><ul style="padding: 0px; margin: 0px 0px 6px 25px;"><li style="">Thoroughness of the research of multiple solutions</li><li style="">Unique solutions explored (i.e., 2+ people shouldn&#39;t research the same option/topic on the same team)</li><li style="">Working Implementation</li><li style="">Thorough yet concise explanation/details on the chosen solution</li></ul></div></div></p>
</td></tr></table>
<table><tr><td> <em>Deliverable 1: </em> Team member Research (2+ people shouldn't research the same option/topic on the same team) </td></tr><tr><td><em>Status: </em> <img width="100" height="20" src="http://via.placeholder.com/400x120/009955/fff?text=Complete"></td></tr>
<tr><td><table><tr><td> <em>Sub-Task 1: </em> Team member 1</td></tr>
<tr><td> <em>Response:</em> <p><span style="color: rgb(220, 221, 222); font-family: Whitney, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size:<br>16px; white-space: break-spaces; background-color: rgba(4, 4, 5, 0.07);">Dominic Quitoni - <br>I did research<br>on Kubernetes as a method for our resilence solution. I also looked into<br>how rabbitmq would work in Google Cloud Service Clusters. Kubernetes is an open<br>source system for automating deployment, and scaling, and allows management of containerized applications.<br>I learned how quick and easy deploying a docker image to a Kubernetes-based<br>cluster and how well it could work for running multiple clusters, one for<br>each VM that we are running currently, with each cluster then being able<br>to manage multiple replicas of the service. Kubernetes on googles cloud allows for<br>automatic scaling with the cluster just spinning up another environment with the image<br>provided, and defined by the configurations. this will also work with rabbitmq with<br>the ability to have the queue mirrored to the other instances of rabbits<br>running in the cluster. federated queues is a type of queue replication that<br>allows a way of balancing the load of a single logical queue across<br>nodes or clusters.  this would nearly eliminate the chance of a message<br>in the queue from being lost in the event that the master rabbit<br>would fail, then the backup/copies of that message would still be able to<br>propagate from the other instance of the rabbit. this can be configured in<br>many different ways based on the needs required, but setting up 3 instances<br>would mean that if the master failed the second one could be set<br>up as the master machine, and the one that failed can be restarted<br>to a safe state. With the environment on GCP this setup handles load<br>balancing handled by the clustering, with it being able to then mirror data<br>to the other queue in the cluster.<br>GCP has the ability to create instance<br>groups that are based on the disk that we have pushed to for<br>our QA build. then is able to handle autoscaling the instances, and able<br>to run health checks if the instance is having problems and will take<br>action to recreate the instance.</span><div><span style="color: rgb(220, 221, 222); font-family: Whitney, &quot;Helvetica Neue&quot;,<br>Helvetica, Arial, sans-serif; font-size: 16px; white-space: break-spaces; background-color: rgba(4, 4, 5, 0.07);"></p><br><p>Pros: The<br>Pros of Kubernetes are that it has tons of great tools built for<br>the open-source software to allow an easier time managing the instances and clusters,<br>allows for an easy way to help ensure 99% uptime, and with google<br>can be set to have separate clusters and copies of the cluster in<br>multiple separate data centers around the world, to prevent against loss of data<br>via physical diasters.</p><br><p>Cons: It can take a lot of configuring to get every<br>part of the systems to work with all their prerequisites, the costs of<br>running so many machines concurrently can add up fast, and the need for<br>a different method of building the website to work more optimally in a<br>container based environment.</span></div><br></p><br></td></tr>
<tr><td> <em>Sub-Task 2: </em> Team member 2</td></tr>
<tr><td> <em>Response:</em> <div><span style="background-color: rgba(4, 4, 5, 0.07);"><font color="#dcddde" face="Whitney, Helvetica Neue, Helvetica, Arial, sans-serif"><span<br>style="font-size: 16px; white-space: break-spaces;">Jia Zhong - </span></font><br></span></div><div><span style="color: rgb(220, 221, 222); font-family: Whitney,<br>&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size: 16px; white-space: break-spaces; background-color: rgba(4, 4, 5,<br>0.07);">First, for this week's assignment, we will need multiple instances. Our group will<br>need to search for a  way to help scale, optimize, and secure<br>our application. I looked into Google cloud load balancing and went more in-depth<br>on its HTTP load balancers. Clouding load balancing helps balance user traffic to<br>multiple backends to avoid lag and conjunction. For HTTP load balancing to work:<br>all the VM need to access external traffic by creating an HTTP firewall<br>rule. All instances will be running with curl. To configure the load balancing,<br>we must first create a static IP address (virtual IPs) and add a<br>legacy HTTP check with the following command "gcloud compute http-health-checks create basic-check." Create<br>a target pool/instance group and add all the VM instances to the pool.<br>Google Cloud Platform has an option that checks how frequently you want to<br>query your system to check if the VM health is in good shape.<br>Then, define the host and path rule that will send traffic to a<br>desired location/proxy or leave it to default if you do not have a<br>specific path. GCP allows us to create load balancing under the network services<br>with two options: a free tier and a premium tier. The main goal<br>is to redirect traffic away from unresponsive nodes. Pros:-single anycast id address <br>will automatically moves traffic to failover backends if your primary backends become unhealthy.<br>Cons: - Required an SSL certificate resource to use in the HTTPS proxy.<br>-Take a lot of time for new VM in GCP to connect to<br>load balancer, and the cost goes up due to having multiple VMs</span><font color="#000000"<br>face="Whitney, Helvetica Neue, Helvetica, Arial, sans-serif"><span style="font-size: 16px; white-space: break-spaces;"><br></span></font></div><br></td></tr>
<tr><td> <em>Sub-Task 3: </em> Team member 3</td></tr>
<tr><td> <em>Response:</em> <div>Smit Joshi -&nbsp;</div>I did research on database replication as a way to achieve<br>resiliency for our application. Since we are using Google Cloud Platform to host<br>our application, I decided to explore Cloud SQL for our MySQL database. It<br>allows for a database instance to be created, known as the primary instance.<br>Copies of this instance can be created called read replicas. Both the primary<br>instance and the read replicas reside in Cloud SQL. As the name for<br>reading replicas suggests, they are only able to perform read operations, but write<br>operations can only be performed on the primary instance. Both the primary instance<br>and its replicas have a separate IP that can be used to connect<br>to them. If the primary database is corrupted or goes down for any<br>reason, the replica instance can take over. This does limit the functionality of<br>the application, for example, users are still able to log in to the<br>application and can view and play trivia games, but functionality to register for<br>new users, or update profiles for existing users will not work while the<br>primary instance is down. Cloud SQL allows for automatic scaling of primary instances<br>based on a variety of factors and replication makes sure that in case<br>something goes wrong, a backup of the entire database is ready and can<br>be promoted to be a primary instance if needed.<br></td></tr>
<tr><td> <em>Sub-Task 4: </em> Team member 4</td></tr>
<tr><td> <em>Response:</em> <div>Javier Artiga -&nbsp;</div><div>From my load balancing readings, I came across HAProxy Enterprise which<br>is not a free service but then learned about its HAProxy Community Edition.<br>It is an open-source load balancer that can be installed on most versions<br>of Linux. HAProxy does not reside on any of the servers but instead<br>will intake incoming connections and send them to the server/servers. HAProxy offers the<br>following; TCP proxy, HTTP reverse-proxy, SSL terminator/imitator, TCP normalizer, HTTP normalize, HTTP fixing<br>tool, content-based switch, server load balancer, traffic regulator, protection against DDOS and service<br>abuse, observation point for network troubleshooting, HTTP compression off-loader, caching proxy, and a<br>FastCGI gateway. HAProxy will process the incoming connections, check the health of the<br>servers it has configured and can talk to other HaProxy nodes. Essentially it<br>works as follows; will take incoming connections from the clients, check processing rules<br>if any exist, and then forward to the list of servers it has<br>configured, based on rules and server health pass it to the appropriate server,<br>and then send the response back out to the client. Haproxy has the<br>following features that would benefit the group; monitoring, high availability, and load balancing.<br>Monitoring will check the server state to make sure that the communication is<br>sent to an active server. It supports more than enough load balancing algorithms<br>but for our purposes, round-robin and least-connections would be best applicable.&nbsp;</div><div>As far as<br>installation it couldn't get any simpler by following these steps for a personal<br>package file to ensure future updates with no issues:</div><div>sudo add-apt-repository ppa:vbernat/haproxy-2.4 -y</div><div>sudo apt<br>install haproxy=2.4.*</div><div><br></div><div>or just</div><div>sudo apt install haproxy</div><div>The configuration to work with is /etc/haproxy/haproxy.cfg&nbsp; This<br>file has four sections to consider, global, defaults, frontend, and backend. Global is<br>self explanatory, frontend will be the IP and port that clients connect to,<br>backend is the IPs/pools of servers where traffic is sent to and defaults<br>are rules/settings which are set to all sections.</div><br></td></tr>
<tr><td> <em>Sub-Task 5: </em> Team member 5</td></tr>
<tr><td> <em>Response:</em> <div>Emily Hontiveros -&nbsp;</div><div><br></div><div>Two-node clusters with a tiebreaker -</div><div>We cannot configure a two-node cluster<br>that it can tolerate the loss of either node because this is impossible.<br>One might expect that if either node fails then you can elect the<br>remaining node as the master, but it is impossible to tell the difference<br>between the failure of a remote node or a mere loss of connectivity<br>between the nodes.</div><div>A possible resiliency solution is adding a third node and making<br>all three nodes master-eligible. A master election requires only two of the three<br>master-eligible nodes, meaning the cluster can tolerate the loss of any one node.<br>This third node will act as a tiebreaker in any case where the<br>two original nodes are disconnected from each other. You can reduce the resources<br>needed of this extra node by making it a dedicated voting-only master-eligible node,<br>also known as a dedicated tiebreaker. A dedicated tiebreaker does not need to<br>be as powerful as the other two nodes because it has no other<br>roles.&nbsp;</div><div>You should also send all client requests to the other two nodes in<br>case one node fails and the requests will not receive a response. Ideally,<br>you should balance your client requests across both of the non-tiebreaker nodes by<br>assigning the address of both nodes when configuring your client to connect to<br>your cluster. Alternatively, you can use a resilient load balancer to balance client<br>requests across the appropriate nodes in your cluster. The Google Cloud service provides<br>a load balancer.</div><div><br></div><div>Pro: A two-node cluster with an additional tiebreaker node is the<br>smallest possible cluster that is suitable for production deployments.</div><div>Con: This solution is only<br>ideal if you use two-nodes, if you have more than 3 nodes, it<br>would be best to specialize these nodes according to their responsibilities</div><br></td></tr>
<tr><td> <em>Sub-Task 6: </em> Team member 6</td></tr>
<tr><td> <em>Response:</em> <p>N/A<br></p><br></td></tr>
</table></td></tr>
<table><tr><td> <em>Deliverable 2: </em> Team solution </td></tr><tr><td><em>Status: </em> <img width="100" height="20" src="http://via.placeholder.com/400x120/009955/fff?text=Complete"></td></tr>
<tr><td><table><tr><td> <em>Sub-Task 1: </em> Mention what solution the team decided upon and why</td></tr>
<tr><td> <em>Response:</em> <p><span style="color: rgb(220, 221, 222); font-family: Whitney, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-size:<br>16px; white-space: break-spaces; background-color: rgba(4, 4, 5, 0.07);">after discussions as a team with<br>comparing the different methods that we all researched, we came to the conclusion<br>of using HAProxy as our solution for keeping our service accessible to the<br>users even though VM instances going down. the HAProxy is used on the<br>APP server so that the user only has one IP that they enter<br>only one and that it will handle redirecting instantly when the first one<br>fails. for the MQ server, haproxy would not have worked as it would<br>not persist the data that is still in the queue, if HAproxy was<br>used in a similar manner it would allow the mq server to be<br>easily targeted by one ip but could potentially lose data that was written<br>to the queue before it could be consumed. So by clustering, in our<br>case 4 instances of MQ, and adding a policy to the cluster making<br>every queue made in it be a High Availability queue that will mirror<br>the data in the queue to the other instances, so it would require<br>all the instances to fail before a users message will be lost.</span><br></p><br></td></tr>
</table></td></tr>
<table><tr><td> <em>Deliverable 3: </em> Evidence of working implementation </td></tr><tr><td><em>Status: </em> <img width="100" height="20" src="http://via.placeholder.com/400x120/009955/fff?text=Complete"></td></tr>
<tr><td><table><tr><td> <em>Sub-Task 1: </em> Show before and after screenshots of the following for app</td></tr>
<tr><td><table><tr><td><img width="768px" src="https://cdn.discordapp.com/attachments/978682357223657492/1002300878360952832/APPgif.gif"/></td></tr>
<tr><td> <em>Caption:</em> <p>I am showing in the gif as to that when the primary app<br>server goes down that the haproxy then fails over to the next instance<br>in the file shown at the end. this shows the ips of the<br>other APP instances<br></p>
</td></tr>
</table></td></tr>
<tr><td> <em>Sub-Task 2: </em> Show before and after screenshots of the following for db</td></tr>
<tr><td><table><tr><td><img width="768px" src="https://cdn.discordapp.com/attachments/985548932304232479/1001883009634537472/registration_Pdb.gif"/></td></tr>
<tr><td> <em>Caption:</em> <p>this gif is showing that the registration and logging in worked.  <br>         db uses cloud based<br>sql service along with two db instances running consumers the second one is<br>a slave of the first, so it is not able to insert into<br>the tables, but is still able to respond to the <br></p>
</td></tr>
<tr><td><img width="768px" src="https://cdn.discordapp.com/attachments/985548932304232479/1001883008732774501/failover.gif"/></td></tr>
<tr><td> <em>Caption:</em> <p>this link shows a gif of the db instance being triggered to failover.<br></p>
</td></tr>
<tr><td><img width="768px" src="https://cdn.discordapp.com/attachments/985548932304232479/1001883009152208897/register_Rdb.gif?width=1417&height=675"/></td></tr>
<tr><td> <em>Caption:</em> <p>this link shows what fuctionality the replica db server is able to do<br>while the main one is down. this allows for data to be pulled<br>from table but doesnt allow for data to be inserted until the main<br>db server comes back online<br></p>
</td></tr>
</table></td></tr>
<tr><td> <em>Sub-Task 3: </em> Show before and after screenshots of the following for api</td></tr>
<tr><td><table><tr><td><img width="768px" src="https://cdn.discordapp.com/attachments/978682357223657492/1002311322614112287/api_res.gif"/></td></tr>
<tr><td> <em>Caption:</em> <p>api resilience is having two separate instances that are able to pull from<br>the api_queue and sending the response to the db.<br></p>
</td></tr>
</table></td></tr>
<tr><td> <em>Sub-Task 4: </em> Show before and after screenshots of the following for mq</td></tr>
<tr><td><table><tr><td><img width="768px" src="https://user-images.githubusercontent.com/70656707/180658901-b5cb842c-12e9-4204-8d63-8ad40d2f90ce.gif"/></td></tr>
<tr><td> <em>Caption:</em> <p>here is a gif showing that the MQ instance going down and the<br>ability for the app and db servers to be redirected to the next<br>instanec of mq. this is done using a failover script that changes the<br>ini files necessary for it to point towards a the other instance in<br>the rabbit mq cluster. <br></p>
</td></tr>
</table></td></tr>
</table></td></tr>
<table><tr><td><em>Grading Link: </em><a rel="noreferrer noopener" href="https://learn.ethereallab.app/homework/IT490-451-M22/it490-milestone-3-resiliency/grade/dwq2" target="_blank">Grading</a></td></tr></table>